{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "from re import compile\n",
    "from requests import get\n",
    "from itertools import chain\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pandas import DataFrame, concat\n",
    "from sys import argv\n",
    "from transliterate import translit\n",
    "from requests.exceptions import ConnectionError, ReadTimeout\n",
    "from json import JSONDecodeError, load\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DVACH = 'https://2ch.hk/'\n",
    "\n",
    "\n",
    "def cut(data):\n",
    "    r = compile(r'<.*?>|>>\\d*|\\(OP\\)|&#(\\d*);|&quot;|&gt;|(http|https):.*')\n",
    "    return r.sub('', punctuate_word(punctuate_sent((data))))\n",
    "\n",
    "\n",
    "def punctuate_sent(data):\n",
    "    r = compile(r'([a-zA-Zа-яА-Я])([.!\\?])')\n",
    "    return r.sub(r'\\1. ', data)\n",
    "\n",
    "\n",
    "def punctuate_word(data):\n",
    "    r = compile(r'([a-zA-Zа-яА-Я])([,])')\n",
    "    return r.sub(r'\\1, ', data)\n",
    "\n",
    "\n",
    "def load_threads(board='b'):\n",
    "    try:\n",
    "        dvach_page = get('https://2ch.hk/{}/catalog.json'.format(board)).json()\n",
    "        return [i['num'] for i in dvach_page['threads']]\n",
    "    except:\n",
    "        print('Нет такой доски.')\n",
    "\n",
    "\n",
    "def load_comments(threads, board='b'):\n",
    "    print('Загружаем комментарии с ' + board)\n",
    "    comments = []\n",
    "\n",
    "    for every_thread in threads:\n",
    "        try:\n",
    "            thread = get(DVACH + board + '/res/' + every_thread + '.json', timeout=5).json()\n",
    "            [comments.append(sent_tokenize(cut(i['comment']))) for i in thread['threads'][0]['posts'] if\n",
    "            len(cut(i['comment'])) > 2]\n",
    "        except:\n",
    "            pass\n",
    "    print('Данные загружены, переходим к сериализации')\n",
    "    return list(chain.from_iterable(comments)), board\n",
    "\n",
    "\n",
    "def serialize_comments(comments, board='b'):\n",
    "    df = DataFrame()\n",
    "    df['comment'] = comments\n",
    "    df.index.names = ['comment_id']\n",
    "    subdir = '../pickle'\n",
    "    try:\n",
    "        file_path = path.join(subdir, board + '.csv')\n",
    "        old_df = DataFrame.from_csv(file_path)\n",
    "        df = concat((df, old_df)).drop_duplicates()\n",
    "        print('Данные смерджены с уже существующими.')\n",
    "    except FileNotFoundError:\n",
    "        print('Сериализованных данных доски ' + board + ' не найдено, сделан новый файл.')\n",
    "    if not path.exists(subdir):\n",
    "        makedirs(subdir)\n",
    "    file_path = path.join(subdir, board + '.csv')\n",
    "    df.to_csv(file_path)\n",
    "    print('Сериализованы данные доски ' + board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boardlist = []\n",
    "\n",
    "fp = urllib.request.urlopen(DVACH)\n",
    "mybytes = fp.read()\n",
    "\n",
    "mystr = mybytes.decode('utf8')\n",
    "fp.close()\n",
    "\n",
    "soup = BeautifulSoup(mystr, 'lxml')\n",
    "\n",
    "for i in soup.find('div', 'board-list-mob').optgroup.findChildren('option'):\n",
    "    boardlist.append(str(i.text)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(name):\n",
    "    if name == 'comment':\n",
    "        return [cut(i[name]) for i in thread['threads'][0]['posts']]\n",
    "    elif name == 'files':\n",
    "        return [len(i[name]) for i in thread['threads'][0]['posts']]\n",
    "    else:\n",
    "        return [i[name] for i in thread['threads'][0]['posts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_name(board, subject):\n",
    "    subject = subject.replace('|', '.')\n",
    "    subject = subject.replace('/', '.')\n",
    "    return '{}_{}.csv'.format(board, translit(subject.lower().replace(' ', '_'), 'ru', reversed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for board in boardlist:\n",
    "    for i, every_thread in enumerate(load_threads(board)[:30]):\n",
    "        try:\n",
    "            thread = get('https://2ch.hk/{0}/res/{1}.json'.format(board, every_thread), timeout=5).json()\n",
    "        except (ConnectionError, ReadTimeout, JSONDecodeError):\n",
    "            continue\n",
    "        thread_subject =  thread['threads'][0]['posts'][0]['subject']\n",
    "        if '#' not in thread_subject or '&#' in thread_subject:\n",
    "            continue\n",
    "        #print(thread_subject)\n",
    "        threads.append({'board': board,\n",
    "                        'thread_subject': thread_subject,\n",
    "                        'comment': get_data('comment'), \n",
    "                        'date': get_data('date'),\n",
    "                        'email': get_data('email'),\n",
    "                        'num': get_data('num'),\n",
    "                        'op': get_data('op'),\n",
    "                        'subject': get_data('subject'),\n",
    "                        'parent': get_data('parent'),\n",
    "                       'files': get_data('files')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in threads:\n",
    "    DataFrame.from_dict(i).to_csv(path.join('2ch-dataset', make_name(i['board'], i['subject'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = concat([DataFrame.from_csv('2ch-dataset/fiz_convict_conditioning_#17.csv'), DataFrame.from_csv('2ch-dataset/fiz_convict_conditioning_#18.csv')]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
