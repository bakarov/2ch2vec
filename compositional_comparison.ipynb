{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, Series\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "from glove import Glove\n",
    "import adagram\n",
    "from gensim.models.wrappers import FastText, Wordrank\n",
    "from embed_utils import Word2VecF, Swivel, cosine_sim, get_adagram_sense_prob, wv\n",
    "from utils.string_utils import morph_parse, make_tokens\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import mpltex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_feature_vec(tokens, num_features, model, make_pca, make_sum):\n",
    "    featureVec = np.zeros(shape=(1, num_features), dtype='float32')\n",
    "    for word in tokens:\n",
    "        if model == 'word2vec':\n",
    "            featureVec = np.add(featureVec, word2vec[word])\n",
    "        elif model == 'wang2vec':\n",
    "            featureVec = np.add(featureVec, wang2vec[word])\n",
    "        elif model == 'glove':\n",
    "            featureVec = np.add(featureVec, wv(glove, word))\n",
    "        elif model == 'word2vecf':\n",
    "            featureVec = np.add(featureVec, w2vf.word2vec(word))\n",
    "        elif model == 'adagram':\n",
    "            featureVec = np.add(featureVec, ada_model.sense_vector(word, get_adagram_sense_prob(ada_model, word)))\n",
    "        elif model == 'fasttext':\n",
    "            featureVec = np.add(featureVec, ft[word])\n",
    "        elif model == 'swivel':\n",
    "            featureVec = np.add(featureVec, np.array(swivel.lookup(word)).squeeze())\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(shape=(1, num_features), dtype='float32')\n",
    "    else:\n",
    "        return np.divide(featureVec, len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "old_err_state = np.seterr(all='raise')\n",
    "\n",
    "def vectorize_message(message1, message2, model, num_features, vocab, make_pca=False, make_sum=False):\n",
    "    tokens1 = make_tokens(message1.lower(), vocab)\n",
    "    tokens2 = make_tokens(message2.lower(), vocab)\n",
    "    fv1 = get_feature_vec(tokens1, num_features, model, make_pca, make_sum)\n",
    "    fv2 = get_feature_vec(tokens2, num_features, model, make_pca, make_sum)\n",
    "    if make_sum:\n",
    "        return fv1.squeeze()+fv2.squeeze()/2\n",
    "    if make_pca:\n",
    "        try:\n",
    "            pca = PCA(n_components=1)\n",
    "            return pca.fit_transform((np.stack((fv1.squeeze(), fv2.squeeze())).T)).squeeze()\n",
    "        except FloatingPointError:\n",
    "            return np.zeros(shape=(1, num_features), dtype='float32')\n",
    "    else:\n",
    "        return np.hstack((fv1, fv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = read_csv(path.join('sim_datasets', 'dsr.csv'))\n",
    "df.post = df.post.apply(morph_parse)\n",
    "df.op_post = df.op_post.apply(morph_parse)\n",
    "Y = df.is_related.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Word2Vec-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(path.join('models','word2vec','all_lem_100'))\n",
    "word2vec_vocab = word2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Glove-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(path.join('models', 'glove' , 'all_lem_100'), 'rb') as fp:\n",
    "    glove = load(fp)\n",
    "glove_vocab = glove.dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Wang2Vec-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wang2vec = KeyedVectors.load_word2vec_format(path.join('models', 'wang2vec', 'wang_skipngram'), binary=True)\n",
    "wang2vec_vocab = wang2vec.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Word2Vec-f-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w2vf = Word2VecF.load(path.join('models', 'word2vecf', '2', 'vecs.npy'), path.join('models', 'word2vecf', '2', 'vecs.vocab'))\n",
    "w2vf_vocab = w2vf._vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Adagram-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ada_model = adagram.VectorModel.load(path.join('models', 'adagram', 'out.pkl'))\n",
    "adagram_vocab = ada_model.dictionary.word2id.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Swivel-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "swivel = Swivel(path.join('models', 'swivel', '2chswivel.txt'), path.join('models', 'swivel', '2chswivel.bin'))\n",
    "swivel_vocab = swivel.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Fasttext-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ft = FastText.load_word2vec_format(path.join('models', 'fasttext', '2ch_model_cbow.vec'))\n",
    "ft_vocab = ft.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Получение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_vectors_dataset(model, vocab, dim, make_pca=False, make_sum=False):\n",
    "    multiplier = 2\n",
    "    if make_pca or make_sum:\n",
    "        multiplier = 1\n",
    "    vectors = np.zeros(shape=(len(df), dim*multiplier), dtype='float32')\n",
    "    for i, m in df.iterrows():\n",
    "        vectors[i] = vectorize_message(m['post'], m['op_post'], model, dim, vocab, make_pca, make_sum)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectors_con = dict()\n",
    "vectors_sum = dict()\n",
    "vectors_con_pca = dict()\n",
    "\n",
    "for (model, dim, vocab) in [\n",
    "                    ('word2vec', word2vec_vocab, 100),\n",
    "                     ('glove', glove_vocab, 100),\n",
    "                     ('wang2vec', wang2vec_vocab, 100),\n",
    "                     ('adagram', adagram_vocab, 100),\n",
    "                     ('word2vecf', w2vf_vocab, 100),\n",
    "                     ('fasttext', ft_vocab, 100),\n",
    "                     ('swivel', swivel_vocab, 100),\n",
    "                     ]:\n",
    "    vectors_con[model] = make_vectors_dataset(model, dim, vocab)\n",
    "    vectors_con_pca[model] = make_vectors_dataset(model, dim, vocab, True)\n",
    "    vectors_sum[model] = make_vectors_dataset(model, dim, vocab, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "SIZE = 30\n",
    "\n",
    "def set_plt_params(title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.suptitle(title, fontsize=SIZE)\n",
    "    plt.grid(False)\n",
    "    plt.axes(frameon = 0)\n",
    "    plt.tick_params(labelsize=SIZE)\n",
    "    seaborn.set_style('white')\n",
    "    plt.ylim([0.725, 0.855])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = {'SUM': [], 'CON': [], 'CON+PCA' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seaborn.set_style('white')\n",
    "\n",
    "for NAME, vectors in [\n",
    "                    ('SUM', vectors_sum),\n",
    "                    ('CON', vectors_con),\n",
    "                    ('CON+PCA', vectors_con_pca)\n",
    "                    ]:\n",
    "    set_plt_params(NAME)\n",
    "\n",
    "    for name, markerstyle, colorstyle in [('glove', 'o', 'brown'),\n",
    "                    ('word2vec', 'v', 'blue'),\n",
    "                    ('wang2vec', '^', 'green'),\n",
    "                    ('word2vecf', '<', 'red'),\n",
    "                    ('adagram', '>', 'orange'),\n",
    "                    ('fasttext', 'd', 'lightblue'),\n",
    "                    ('swivel', 'p', 'olive'),\n",
    "                    ]:\n",
    "        estimator = KNeighborsClassifier(n_neighbors = 3, algorithm='brute', metric='cosine')\n",
    "        cv = ShuffleSplit(n_splits=10, test_size=0.01, random_state=0)\n",
    "        train_sizes=np.linspace(0.01, 0.99, 10)\n",
    "        train_sizes, train_scores, test_scores = learning_curve(estimator, vectors[name], \n",
    "                                                                Y, cv=cv, train_sizes=train_sizes)\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        results[NAME].append({'model' : name, 'score' : train_scores_mean})\n",
    "        plt.plot(train_sizes, train_scores_mean, marker=markerstyle, markersize=15, label=name, linewidth=3, color=colorstyle)\n",
    "\n",
    "    plt.grid(True, axis='y', linewidth=1, color='black')\n",
    "    if NAME == 'CON+PCA':\n",
    "        plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1), prop={'size':SIZE})\n",
    "    plt.savefig('{}.png'.format(NAME), bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CON': [{'model': 'glove',\n",
       "   'score': array([ 0.78846154,  0.76389776,  0.77366667,  0.7740699 ,  0.7802385 ,\n",
       "           0.78097194,  0.78369565,  0.78879607,  0.79138674,  0.79336911])},\n",
       "  {'model': 'word2vec',\n",
       "   'score': array([ 0.77307692,  0.81980831,  0.83233333,  0.83359639,  0.83492334,\n",
       "           0.84079398,  0.84370709,  0.84383292,  0.84345392,  0.84308164])},\n",
       "  {'model': 'wang2vec',\n",
       "   'score': array([ 0.78461538,  0.82492013,  0.83033333,  0.8313416 ,  0.83211244,\n",
       "           0.84182067,  0.84748284,  0.84923833,  0.85099053,  0.85454197])},\n",
       "  {'model': 'word2vecf',\n",
       "   'score': array([ 0.76153846,  0.79233227,  0.79333333,  0.78996618,  0.79565588,\n",
       "           0.79760438,  0.80291762,  0.80329238,  0.80766581,  0.81023381])},\n",
       "  {'model': 'adagram',\n",
       "   'score': array([ 0.78846154,  0.76389776,  0.788     ,  0.79470124,  0.79488927,\n",
       "           0.79794661,  0.80108696,  0.80358722,  0.80676141,  0.8074358 ])},\n",
       "  {'model': 'fasttext',\n",
       "   'score': array([ 0.77692308,  0.82268371,  0.8405    ,  0.84363021,  0.8451448 ,\n",
       "           0.85023956,  0.85160183,  0.85090909,  0.85073213,  0.85320046])},\n",
       "  {'model': 'swivel',\n",
       "   'score': array([ 0.77307692,  0.82108626,  0.83266667,  0.83010147,  0.83211244,\n",
       "           0.83812457,  0.84330664,  0.84594595,  0.8496124 ,  0.85216558])}],\n",
       " 'CON+PCA': [{'model': 'glove',\n",
       "   'score': array([ 0.73076923,  0.78785942,  0.79083333,  0.79954904,  0.79931857,\n",
       "           0.80246407,  0.80532037,  0.80638821,  0.81124031,  0.81502491])},\n",
       "  {'model': 'word2vec',\n",
       "   'score': array([ 0.72692308,  0.79329073,  0.80866667,  0.81871477,  0.82155026,\n",
       "           0.82614648,  0.82854691,  0.82987715,  0.82984496,  0.83384438])},\n",
       "  {'model': 'wang2vec',\n",
       "   'score': array([ 0.76153846,  0.81565495,  0.81833333,  0.82299887,  0.82649063,\n",
       "           0.83655031,  0.84256293,  0.84275184,  0.84328165,  0.84407819])},\n",
       "  {'model': 'word2vecf',\n",
       "   'score': array([ 0.77307692,  0.79297125,  0.79016667,  0.78568207,  0.79063032,\n",
       "           0.79500342,  0.79610984,  0.7963145 ,  0.80163652,  0.80337294])},\n",
       "  {'model': 'adagram',\n",
       "   'score': array([ 0.73461538,  0.76805112,  0.76766667,  0.77914318,  0.78100511,\n",
       "           0.78925394,  0.7965103 ,  0.79867322,  0.80073213,  0.80578766])},\n",
       "  {'model': 'fasttext',\n",
       "   'score': array([ 0.76538462,  0.8       ,  0.82466667,  0.82897407,  0.83083475,\n",
       "           0.83572895,  0.84004577,  0.84132678,  0.84112834,  0.84327328])},\n",
       "  {'model': 'swivel',\n",
       "   'score': array([ 0.76153846,  0.79265176,  0.81466667,  0.81431793,  0.82155026,\n",
       "           0.82648871,  0.83295195,  0.83390663,  0.8369509 ,  0.83737064])}],\n",
       " 'SUM': [{'model': 'glove',\n",
       "   'score': array([ 0.76923077,  0.77603834,  0.7865    ,  0.79312289,  0.7927598 ,\n",
       "           0.79329227,  0.79765446,  0.80044226,  0.80542636,  0.80931391])},\n",
       "  {'model': 'word2vec',\n",
       "   'score': array([ 0.74615385,  0.79616613,  0.811     ,  0.81251409,  0.81839864,\n",
       "           0.82806297,  0.83186499,  0.83331695,  0.83484065,  0.83376773])},\n",
       "  {'model': 'wang2vec',\n",
       "   'score': array([ 0.78461538,  0.814377  ,  0.827     ,  0.83269448,  0.83211244,\n",
       "           0.83908282,  0.84159039,  0.84216216,  0.84582257,  0.84867765])},\n",
       "  {'model': 'word2vecf',\n",
       "   'score': array([ 0.77307692,  0.78370607,  0.768     ,  0.77046223,  0.7729983 ,\n",
       "           0.78110883,  0.78083524,  0.7841769 ,  0.79095607,  0.79279417])},\n",
       "  {'model': 'adagram',\n",
       "   'score': array([ 0.72692308,  0.76709265,  0.77466667,  0.78196167,  0.79020443,\n",
       "           0.79041752,  0.79948513,  0.80191646,  0.80680448,  0.80896895])},\n",
       "  {'model': 'fasttext',\n",
       "   'score': array([ 0.77692308,  0.80351438,  0.81733333,  0.81905299,  0.81865417,\n",
       "           0.8238193 ,  0.82677346,  0.82776413,  0.83096469,  0.83323112])},\n",
       "  {'model': 'swivel',\n",
       "   'score': array([ 0.73461538,  0.8057508 ,  0.82083333,  0.82187148,  0.82010221,\n",
       "           0.82861054,  0.83358124,  0.83552826,  0.84061154,  0.84239172])}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сравнение косинусного расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93155136090587609"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(ada_model.sense_vector('кошка', get_adagram_sense_prob(ada_model, 'кошка')),\n",
    "                      ada_model.sense_vector('собака', get_adagram_sense_prob(ada_model, 'собака')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25567083116885791"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(ft['кошка'], ft['собака'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
