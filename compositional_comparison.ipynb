{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, Series\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "from glove import Glove\n",
    "import adagram\n",
    "from gensim.models.wrappers import FastText, Wordrank\n",
    "from embed_utils import Word2VecF, Swivel, cosine_sim, get_adagram_sense_prob, wv\n",
    "from utils.string_utils import morph_parse, make_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "old_err_state = np.seterr(all='raise')\n",
    "\n",
    "def vectorize_message_2(sentence, model, num_features, vocab):\n",
    "    featureVec = np.zeros((num_features), dtype='float32')\n",
    "    nwords = 0\n",
    "    \n",
    "    tokens = make_tokens(sentence.lower(), vocab)\n",
    "\n",
    "    for word in tokens:\n",
    "        if word in vocab: \n",
    "            if model == 'word2vec':\n",
    "                featureVec = np.add(featureVec, word2vec[word])\n",
    "            elif model == 'wang2vec':\n",
    "                featureVec = np.add(featureVec, wang2vec[word])\n",
    "            elif model == 'glove':\n",
    "                featureVec = np.add(featureVec, wv(glove, word))\n",
    "            elif model == 'word2vecf':\n",
    "                featureVec = np.add(featureVec, w2vf.word2vec(word))\n",
    "            elif model == 'adagram':\n",
    "                featureVec = np.add(featureVec, ada_model.sense_vector(word, get_adagram_sense_prob(ada_model, word)))\n",
    "            elif model == 'fasttext':\n",
    "                featureVec = np.add(featureVec, ft[word])\n",
    "            elif model == 'bow':\n",
    "                featureVec = np.add(featureVec, bow[word])\n",
    "            elif model == 'swivel':\n",
    "                featureVec = np.add(featureVec, swivel.lookup(word))\n",
    "            nwords = nwords + 1\n",
    "    try:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    except FloatingPointError:\n",
    "         featureVec = np.zeros((num_features), dtype='float32')\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_feature_vec(tokens, num_features, model, do_pca=False):\n",
    "    featureVec = np.zeros(shape=(1, num_features), dtype='float32')\n",
    "    nwords = 0\n",
    "    for word in tokens:\n",
    "        if model == 'word2vec':\n",
    "            featureVec = np.add(featureVec, word2vec[word])\n",
    "        elif model == 'wang2vec':\n",
    "            featureVec = np.add(featureVec, wang2vec[word])\n",
    "        elif model == 'glove':\n",
    "            featureVec = np.add(featureVec, wv(glove, word))\n",
    "        elif model == 'word2vecf':\n",
    "            featureVec = np.add(featureVec, w2vf.word2vec(word))\n",
    "        elif model == 'adagram':\n",
    "            featureVec = np.add(featureVec, ada_model.sense_vector(word, get_adagram_sense_prob(ada_model, word)))\n",
    "        elif model == 'fasttext':\n",
    "            featureVec = np.add(featureVec, ft[word])\n",
    "        elif model == 'bow':\n",
    "            featureVec = np.add(featureVec, bow[word])\n",
    "        elif model == 'swivel':\n",
    "            featureVec = np.add(featureVec, swivel.lookup(word))\n",
    "        nwords = nwords + 1\n",
    "    if do_pca:\n",
    "        pca = PCA(n_components=1)\n",
    "        try:\n",
    "            return pca.fit_transform((np.stack((fv1, fv2)).T)).squeeze()\n",
    "        except FloatingPointError:\n",
    "            return np.zeros(shape=(num_features), dtype='float32')\n",
    "    else:\n",
    "        try:\n",
    "            return np.divide(featureVec, nwords)\n",
    "        except FloatingPointError:\n",
    "            return np.zeros(shape=(1,num_features), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "old_err_state = np.seterr(all='raise')\n",
    "\n",
    "def vectorize_message(message1, message2, model, num_features, vocab):\n",
    "    tokens1 = make_tokens(message1.lower(), vocab)\n",
    "    tokens2 = make_tokens(message2.lower(), vocab)\n",
    "    fv1 = get_feature_vec(tokens1, num_features, model)\n",
    "    fv2 = get_feature_vec(tokens2, num_features, model)\n",
    "    return np.hstack((fv1, fv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = read_csv('anno2ch/annotated.csv', encoding='cp1251').dropna()\n",
    "df.comment = df.comment.apply(morph_parse)\n",
    "df.reference = df.reference.apply(morph_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_unl = read_csv('anno2ch/annotated.csv', encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y = df['labels'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Word2Vec-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load('models/word2vec/all_lem_100')\n",
    "word2vec_vocab = word2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Glove-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('models/glove/all_lem_100', 'rb') as fp:\n",
    "    glove = load(fp)\n",
    "glove_vocab = glove.dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Wang2Vec-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wang2vec = KeyedVectors.load_word2vec_format('models/wang2vec/all_lem_100_cwindow', binary=True)\n",
    "wang2vec_vocab = wang2vec.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Word2Vec-f-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "w2vf = Word2VecF.load(path.join('models/word2vecf', 'vecs.npy'), path.join('models/word2vecf', 'vecs.vocab'))\n",
    "w2vf_vocab = w2vf._vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Adagram-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ada_model = adagram.VectorModel.load('models/adagram/all_lem_100.pkl')\n",
    "adagram_vocab = ada_model.dictionary.word2id.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка BOW-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "with open('models/tfidf/all_lem', 'rb') as fp:\n",
    "    bow = load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Swivel-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "swivel = Swivel('models/swivel/vocab_100.txt', 'models/swivel/vecs_100.bin')\n",
    "swivel_vocab = swivel.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Загрузка Fasttext-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ft = FastText.load_word2vec_format('models/fasttext/all_100_skipgram.vec')\n",
    "ft_vocab = ft.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Получение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_vectors_dataset(model, vocab, dim):\n",
    "    vectors = np.zeros(shape=(len(df), dim*2), dtype='float32')\n",
    "    for i, m in df.iterrows():\n",
    "        vectors[i] = vectorize_message(m['comment'], m['reference'], model, dim, vocab)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectors_mo = dict()\n",
    "\n",
    "for (model, dim, vocab) in [('word2vec', word2vec_vocab, 100),\n",
    "                     ('glove', glove_vocab, 100),\n",
    "                     ('wang2vec', wang2vec_vocab, 100),\n",
    "                     ('adagram', adagram_vocab, 100),\n",
    "                     ('word2vecf', w2vf_vocab, 100),\n",
    "                     ('fasttext', ft_vocab, 100),\n",
    "                     ('swivel', swivel_vocab, 100),\n",
    "                     ('bow', bow, 1)]:\n",
    "    vectors_mo[model] = make_vectors_dataset(model, dim, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def set_plt_params():\n",
    "    title_font = {'size':'80', 'color':'black', 'weight':'normal',\n",
    "                  'verticalalignment':'bottom'} \n",
    "    axis_font = {'size':'80'}\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.suptitle('(b) Concatenation', fontsize=90)\n",
    "    plt.grid(False)\n",
    "    plt.axes(frameon = 0)\n",
    "    plt.tick_params(labelsize=60)\n",
    "    plt.ylim([0.76, 0.86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_plt_params()\n",
    "results = []\n",
    "\n",
    "seaborn.set_style('white', {'grid' : False})\n",
    "\n",
    "for name, lstyle in [('glove', 'dotted'),\n",
    "                ('word2vec', 'dashed'),\n",
    "                ('wang2vec', 'dashdot'),\n",
    "                ('word2vecf',  (0, (20,20))),\n",
    "                ('adagram', (0,(10,10))),\n",
    "                ('fasttext','solid'),\n",
    "                ('bow',(0,(30,30))),\n",
    "                ('swivel',(0,(40,40))),\n",
    "                ]:\n",
    "    #estimator = KNeighborsClassifier(n_neighbors = 3, algorithm='brute', metric='cosine')\n",
    "    estimator = SVC(kernel='poly')\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "    train_sizes=np.linspace(0.1, 0.9, 5)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, vectors_mo[name], \n",
    "                                                            Y, cv=cv, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    results.append({'model' : name, 'score' : train_scores_mean})\n",
    "    plt.plot(train_sizes, train_scores_mean, marker='o', markersize=10, label=name, linewidth=10, linestyle=lstyle)\n",
    "\n",
    "#plt.savefig('classifiers_concat.png', bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'glove',\n",
       "  'score': array([ 0.79926471,  0.81902439,  0.82383041,  0.8353187 ,  0.8338749 ])},\n",
       " {'model': 'word2vec',\n",
       "  'score': array([ 0.81102941,  0.83487805,  0.84312865,  0.84555904,  0.84922827])},\n",
       " {'model': 'wang2vec',\n",
       "  'score': array([ 0.78455882,  0.83097561,  0.83625731,  0.84117032,  0.84459789])},\n",
       " {'model': 'word2vecf',\n",
       "  'score': array([ 0.74779412,  0.73780488,  0.73567251,  0.73615465,  0.73428107])},\n",
       " {'model': 'adagram',\n",
       "  'score': array([ 0.77573529,  0.79365854,  0.80131579,  0.80679206,  0.81632819])},\n",
       " {'model': 'fasttext',\n",
       "  'score': array([ 0.8125    ,  0.82609756,  0.83596491,  0.84054336,  0.84337937])},\n",
       " {'model': 'bow',\n",
       "  'score': array([ 0.74779412,  0.76097561,  0.75628655,  0.74702194,  0.72778229])},\n",
       " {'model': 'swivel',\n",
       "  'score': array([ 0.8125    ,  0.83292683,  0.84035088,  0.84869383,  0.85264013])}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
